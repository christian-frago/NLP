{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e96be74a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import spacy\n",
    "import classy_classification\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def process_text(all_text, filename):\n",
    "    #Open and Read all Training Data\n",
    "\n",
    "    with open ('trainset/Topic/Adult.txt', \"r\") as f:\n",
    "        Adult = f.read().splitlines()\n",
    "\n",
    "    with open ('trainset/Topic/Arts and Entertainment.txt', \"r\") as f:\n",
    "        ArtsEntertainment = f.read().splitlines()\n",
    "\n",
    "    with open ('trainset/Topic/Autos and Vehicles.txt', \"r\") as f:\n",
    "        AutosVehicles = f.read().splitlines()\n",
    "\n",
    "    with open ('trainset/Topic/Beauty and Fitness.txt', \"r\") as f:\n",
    "        BeautyFitness = f.read().splitlines()\n",
    "\n",
    "    with open ('trainset/Topic/Business and Industrial.txt', \"r\") as f:\n",
    "        BusinessIndustrial = f.read().splitlines()\n",
    "\n",
    "    with open ('trainset/Topic/Computers and Electronics.txt', \"r\") as f:\n",
    "        ComputersElectronics = f.read().splitlines()\n",
    "\n",
    "    with open ('trainset/Topic/Finance.txt', \"r\") as f:\n",
    "        Finance = f.read().splitlines()\n",
    "\n",
    "    with open ('trainset/Topic/Food and Drink.txt', \"r\") as f:\n",
    "        FoodDrink = f.read().splitlines()\n",
    "\n",
    "    with open ('trainset/Topic/Games.txt', \"r\") as f:\n",
    "        Games = f.read().splitlines()\n",
    "\n",
    "    with open ('trainset/Topic/Health.txt', \"r\") as f:\n",
    "        Health = f.read().splitlines()\n",
    "\n",
    "    with open ('trainset/Topic/Hobbies and Leisure.txt', \"r\") as f:\n",
    "        HobbiesLeisure = f.read().splitlines()\n",
    "\n",
    "    with open ('trainset/Topic/Home and Garden.txt', \"r\") as f:\n",
    "        HomeGarden = f.read().splitlines()\n",
    "\n",
    "    with open ('trainset/Topic/Internet and Telecom.txt', \"r\") as f:\n",
    "        InternetTelecom = f.read().splitlines()\n",
    "\n",
    "    with open ('trainset/Topic/Jobs and Education.txt', \"r\") as f:\n",
    "        JobsEducation = f.read().splitlines()\n",
    "\n",
    "    with open ('trainset/Topic/Law and Government.txt', \"r\") as f:\n",
    "        LawGovernment = f.read().splitlines()\n",
    "\n",
    "    with open ('trainset/Topic/News.txt', \"r\") as f:\n",
    "        News = f.read().splitlines()\n",
    "\n",
    "    with open ('trainset/Topic/Online Communities.txt', \"r\") as f:\n",
    "        OnlineCommunities = f.read().splitlines()\n",
    "\n",
    "    with open ('trainset/Topic/People and Society.txt', \"r\") as f:\n",
    "        PeopleSociety = f.read().splitlines()\n",
    "\n",
    "    with open ('trainset/Topic/Pets and Animals.txt', \"r\") as f:\n",
    "        PetsAnimals = f.read().splitlines()\n",
    "\n",
    "    with open ('trainset/Topic/Real Estate.txt', \"r\") as f:\n",
    "        RealEstate = f.read().splitlines()\n",
    "\n",
    "    with open ('trainset/Topic/Reference.txt', \"r\") as f:\n",
    "        Reference = f.read().splitlines()\n",
    "\n",
    "    with open ('trainset/Topic/Science.txt', \"r\") as f:\n",
    "        Science = f.read().splitlines()\n",
    "\n",
    "    with open ('trainset/Topic/Sensitive Subjects.txt', \"r\") as f:\n",
    "        SensitiveSubjects = f.read().splitlines()\n",
    "\n",
    "    with open ('trainset/Topic/Shopping.txt', \"r\") as f:\n",
    "        Shopping = f.read().splitlines()\n",
    "\n",
    "    with open ('trainset/Topic/Sports.txt', \"r\") as f:\n",
    "        Sports = f.read().splitlines()\n",
    "\n",
    "    with open ('trainset/Topic/Travel.txt', \"r\") as f:\n",
    "        Travel = f.read().splitlines()\n",
    "\n",
    "        \n",
    "    print(\"Topic Classification Training data read!\")\n",
    "    \n",
    "    data = {}\n",
    "    data[\"Adult\"] = Adult\n",
    "    data[\"Arts and Entertainment\"] = ArtsEntertainment\n",
    "    data[\"Autos and Vehicles\"] = AutosVehicles\n",
    "    data[\"Beauty and Fitness\"] = BeautyFitness\n",
    "    data[\"Business and Industrial\"] = BusinessIndustrial\n",
    "    data[\"Computers and Electronics\"] = ComputersElectronics\n",
    "    data[\"Finance\"] = Finance\n",
    "    data[\"Food and Drink\"] = FoodDrink\n",
    "    data[\"Games\"] = Games\n",
    "    data[\"Health\"] = Health\n",
    "    data[\"Hobbies and Leisure\"] = HobbiesLeisure\n",
    "    data[\"Home and Garden\"] = HomeGarden\n",
    "    data[\"Internet and Telecom\"] = InternetTelecom\n",
    "    data[\"Jobs and Education\"] = JobsEducation\n",
    "    data[\"Law and Government\"] = LawGovernment\n",
    "    data[\"News\"] = News\n",
    "    data[\"Online Communities\"] = OnlineCommunities\n",
    "    data[\"People and Society\"] = PeopleSociety\n",
    "    data[\"Pets and Animals\"] = PetsAnimals\n",
    "    data[\"Real Estate\"] = RealEstate\n",
    "    data[\"Reference\"] = Reference\n",
    "    data[\"Science\"] = Science\n",
    "    data[\"Sensitive Subjects\"] = SensitiveSubjects\n",
    "    data[\"Shopping\"] = Shopping\n",
    "    data[\"Sports\"] = Sports\n",
    "    data[\"Travel\"] = Travel\n",
    "\n",
    "    print(\"Applying Text Topic Classification Model to :\", filename)\n",
    "    \n",
    "    #Apply Classy Model\n",
    "    nlp = spacy.blank(\"en\")\n",
    "    nlp.add_pipe(\n",
    "        \"text_categorizer\", \n",
    "        config={\n",
    "            \"data\": data, \n",
    "            \"model\": \"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\",\n",
    "            \"device\": \"cpu\"\n",
    "        }\n",
    "    ) \n",
    "    \n",
    "    print(\"Applying sentencizer!\")\n",
    "    sentence_model = spacy.blank(\"en\")\n",
    "    sentence_model.add_pipe(\"sentencizer\")\n",
    "    \n",
    "    print(\"Segmentation begin:\")\n",
    "    segment_size = 100000  # Define the desired segment size\n",
    "\n",
    "    num_segments = len(all_text) // segment_size + 1  # Calculate the number of segments\n",
    "\n",
    "    final_data = []\n",
    "\n",
    "    for i in range(num_segments):\n",
    "        start_idx = i * segment_size\n",
    "        end_idx = (i + 1) * segment_size\n",
    "        segment = all_text[start_idx:end_idx]\n",
    "\n",
    "        sentences = sentence_model(segment)\n",
    "\n",
    "        for sentence in sentences.sents:\n",
    "            doc = nlp(sentence.text)\n",
    "            final_data.append({\"sentence\": doc.text, \"cats\": doc._.cats})\n",
    "\n",
    "    # Extract the \"sentence\" and \"cats\" data from the final_data list, and trim spaces\n",
    "    sentences = [item[\"sentence\"].strip() for item in final_data]\n",
    "    categories_data = [item[\"cats\"] for item in final_data]\n",
    "\n",
    "    # Create the DataFrame with the \"Sentence\" column\n",
    "    df_cat = pd.DataFrame({\"Sentence\": sentences})\n",
    "\n",
    "    print(\"Composing the dataframe!\")\n",
    "          \n",
    "    # Add the category columns to the DataFrame\n",
    "    category_columns = [\n",
    "        \"Adult\",\n",
    "        \"Arts and Entertainment\",\n",
    "        \"Autos and Vehicles\",\n",
    "        \"Beauty and Fitness\",\n",
    "        \"Business and Industrial\",\n",
    "        \"Computers and Electronics\",\n",
    "        \"Finance\",\n",
    "        \"Food and Drink\",\n",
    "        \"Games\",\n",
    "        \"Health\",\n",
    "        \"Hobbies and Leisure\",\n",
    "        \"Home and Garden\",\n",
    "        \"Internet and Telecom\",\n",
    "        \"Jobs and Education\",\n",
    "        \"Law and Government\",\n",
    "        \"News\",\n",
    "        \"Online Communities\",\n",
    "        \"People and Society\",\n",
    "        \"Pets and Animals\",\n",
    "        \"Real Estate\",\n",
    "        \"Reference\",\n",
    "        \"Science\",\n",
    "        \"Sensitive Subjects\",\n",
    "        \"Shopping\",\n",
    "        \"Sports\",\n",
    "        \"Travel\"\n",
    "    ]\n",
    "\n",
    "    for category in category_columns:\n",
    "        df_cat[category] = [data[category] for data in categories_data]\n",
    "\n",
    "    # Convert the probability values to percentages and round to two decimal places\n",
    "    df_cat[category_columns] = (df_cat[category_columns] * 100).round(6)\n",
    "\n",
    "    # Add a new column with the category_column name that has the highest value\n",
    "    df_cat['Category_Tag'] = df_cat[category_columns].idxmax(axis=1)\n",
    "\n",
    "    # Add a new column for the Filename\n",
    "    df_cat['Filename'] = filename\n",
    "\n",
    "    # Generate the CSV file path\n",
    "    csv_filename = os.path.join(\"dataset\", \"TopicClassification.csv\")\n",
    "\n",
    "    # Create the 'dataset' directory if it doesn't exist\n",
    "    os.makedirs(os.path.dirname(csv_filename), exist_ok=True)\n",
    "\n",
    "    print(\"Creating / Updating Topic CSV file\")\n",
    "          \n",
    "    # Check if the CSV file already exists\n",
    "    if os.path.exists(csv_filename):\n",
    "        # Load the existing CSV file into a DataFrame\n",
    "        df_existing = pd.read_csv(csv_filename)\n",
    "\n",
    "        # Append the new data to the existing DataFrame\n",
    "        df_combined = pd.concat([df_existing, df_cat], ignore_index=True)\n",
    "    else:\n",
    "        # If the CSV file doesn't exist, just save the new DataFrame directly\n",
    "        df_combined = df_cat\n",
    "\n",
    "    # Save the combined DataFrame to the CSV file\n",
    "    df_combined.to_csv(csv_filename, index=False)\n",
    "    print(\"Topic Classification completed!\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    if len(sys.argv) != 3:\n",
    "        print(\"Usage: python extract_data_type.py <all_text> <filename>\")\n",
    "    else:\n",
    "        all_text = sys.argv[1]\n",
    "        filename = sys.argv[2]\n",
    "        process_text(all_text, filename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
